# -*- coding: utf-8 -*-
"""
SafeScore - Pipeline principal
coletar â†’ pontuar â†’ salvar CSV â†’ alertar â†’ (opcional) loop automÃ¡tico

NOVIDADES:
- Modo contÃ­nuo (--daemon): coleta em intervalos fixos, aplicando scoring e salvando.
- Monitoramento por carteiras:
    * --monitor-watchlist         â†’ usa endereÃ§os do app/data/watchlist.csv
    * --monitor-addresses=...     â†’ lista adicional via CLI
    * ETH_MONITOR_ADDRESSES=...   â†’ lista adicional via variÃ¡vel de ambiente
    * --require-match             â†’ sÃ³ processa transaÃ§Ãµes que envolvam os endereÃ§os monitorados
- DeduplicaÃ§Ã£o por tx_id (nÃ£o regrava o que jÃ¡ foi processado).
- MantÃ©m histÃ³rico em memÃ³ria para regra de VELOCIDADE.

Obs.: O dashboard (Streamlit) continua apenas LENDO os CSVs produzidos.
"""

import os
import csv
import json
import sys
import time
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Dict, Any, Set, Tuple

# Carrega .env se existir
try:
    from dotenv import load_dotenv  # type: ignore
    load_dotenv()
except Exception:
    pass

from app.engine.scoring import ScoreEngine
from app.alerts.telegram import TelegramAlerter
from app.collectors.mock_collector import load_input_or_mock

def try_load_eth_collector():
    """Import lazy do coletor ETH (evita falha quando usuÃ¡rio usa mock)."""
    try:
        from app.collectors.eth_collector import load_from_eth  # type: ignore
        return load_from_eth
    except Exception:
        return None

# ---------------------- Caminhos ---------------------- #
DATA_DIR = Path("app/data")
TX_CSV = DATA_DIR / "transactions.csv"
DAY_FMT = "transactions_%Y%m%d.csv"
PENDING_CSV = DATA_DIR / "pending_review.csv"
KNOWN_CSV = DATA_DIR / "known_addresses.csv"
WATCHLIST_CSV = DATA_DIR / "watchlist.csv"

# ---------------------- Utilidades ---------------------- #
def safe_text(text: str) -> str:
    """Sanitiza strings para evitar problemas de PDF/CSV com latin-1."""
    if text is None:
        return ""
    t = str(text)
    t = (
        t.replace("â€”", "-").replace("â€“", "-").replace("â€¦", "...")
         .replace("â‰¥", ">=").replace("â‰¤", "<=").replace("â€¢", "-")
    )
    return t.encode("latin-1", "replace").decode("latin-1")

def ensure_data_files():
    """Garante a estrutura mÃ­nima de dados/listas (idempotente)."""
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    # known_addresses
    if not KNOWN_CSV.exists():
        with KNOWN_CSV.open("w", newline="", encoding="utf-8") as f:
            csv.DictWriter(f, fieldnames=["address","first_seen"]).writeheader()
    # listas base (se foram apagadas)
    def _ensure(path: Path, header: list[str], rows: list[Dict[str, Any]] | None = None):
        if path.exists(): return
        with path.open("w", newline="", encoding="utf-8") as f:
            w = csv.DictWriter(f, fieldnames=header)
            w.writeheader()
            for r in (rows or []): w.writerow(r)
    _ensure(DATA_DIR / "blacklist.csv", ["address","reason"], [])
    _ensure(WATCHLIST_CSV, ["address","note"], [])
    _ensure(DATA_DIR / "sensitive_tokens.csv", ["token"], [])
    _ensure(DATA_DIR / "sensitive_methods.csv", ["method"], [])

def read_known_addresses() -> Set[str]:
    if not KNOWN_CSV.exists(): return set()
    with KNOWN_CSV.open("r", encoding="utf-8") as f:
        return {row["address"].strip().lower() for row in csv.DictReader(f) if row.get("address")}

def append_known_address(addr: str):
    addr = (addr or "").strip().lower()
    if not addr: return
    known = read_known_addresses()
    if addr in known: return
    with KNOWN_CSV.open("a", newline="", encoding="utf-8") as f:
        csv.DictWriter(f, fieldnames=["address","first_seen"]).writerow(
            {"address": addr, "first_seen": datetime.now(timezone.utc).isoformat()}
        )

def read_prev_transactions() -> List[Dict[str, Any]]:
    if not TX_CSV.exists(): return []
    with TX_CSV.open("r", encoding="utf-8") as f:
        return list(csv.DictReader(f))

def load_seen_tx_ids() -> Set[str]:
    """Carrega conjunto de tx_ids jÃ¡ processados (dedupe)."""
    if not TX_CSV.exists(): return set()
    with TX_CSV.open("r", encoding="utf-8") as f:
        return {row.get("tx_id","") for row in csv.DictReader(f)}

def _write_rows_to(path: Path, rows: List[Dict[str, Any]], header: list[str]):
    new_file = not path.exists()
    with path.open("a", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=header)
        if new_file: w.writeheader()
        w.writerows(rows)

def write_transactions(rows: List[Dict[str, Any]]):
    header = [
        "tx_id","timestamp","from_address","to_address","amount","token","method","chain",
        "is_new_address","velocity_last_window","score","penalty_total","reasons","explain"
    ]
    if not rows: return
    _write_rows_to(TX_CSV, rows, header)
    day_file = DATA_DIR / datetime.now().strftime(DAY_FMT)
    _write_rows_to(day_file, rows, header)

def append_pending(rows: List[Dict[str, Any]]):
    if not rows: return
    header = [
        "tx_id","timestamp","from_address","to_address","amount","token","method","chain",
        "score","penalty_total","reasons","explain"
    ]
    pend = []
    for r in rows:
        pend.append({
            "tx_id": r["tx_id"],
            "timestamp": r["timestamp"],
            "from_address": r["from_address"],
            "to_address": r["to_address"],
            "amount": r["amount"],
            "token": r["token"],
            "method": r["method"],
            "chain": r["chain"],
            "score": r["score"],
            "penalty_total": r.get("penalty_total", 0),
            "reasons": r["reasons"],
            "explain": r.get("explain","{}"),
        })
    _write_rows_to(PENDING_CSV, pend, header)

def abbreviate(addr: str) -> str:
    if not addr: return ""
    return addr if len(addr) <= 10 else f"{addr[:6]}â€¦{addr[-4:]}"

# ---------------------- Monitoramento de endereÃ§os ---------------------- #
def load_watch_addresses(from_watchlist: bool, extra_cli: str | None, extra_env: str | None) -> Set[str]:
    """
    Retorna o conjunto de endereÃ§os a monitorar (lowercase).
    - from_watchlist: lÃª app/data/watchlist.csv (coluna 'address').
    - extra_cli/extra_env: listas comma-separated adicionais.
    """
    addrs: Set[str] = set()

    def _split_list(s: str) -> List[str]:
        return [x.strip().lower() for x in s.split(",") if x.strip()]

    if from_watchlist and WATCHLIST_CSV.exists():
        with WATCHLIST_CSV.open("r", encoding="utf-8") as f:
            for row in csv.DictReader(f):
                a = (row.get("address") or "").strip().lower()
                if a: addrs.add(a)

    if extra_env:
        for a in _split_list(extra_env):
            addrs.add(a)

    if extra_cli:
        for a in _split_list(extra_cli):
            addrs.add(a)

    return addrs

def filter_by_addresses(txs: List[Dict[str, Any]], watch: Set[str], require_match: bool) -> List[Dict[str, Any]]:
    """
    Se require_match=True, retorna apenas transaÃ§Ãµes que envolvam 'watch'.
    Caso contrÃ¡rio:
      - Se watch estiver vazio â†’ retorna todas.
      - Se watch tiver itens â†’ retorna todas (para manter visÃ£o geral), mas a watchlist pesarÃ¡ no score.
    """
    if not require_match or not watch:
        return txs
    out = []
    for tx in txs:
        fr = (tx.get("from_address") or "").lower()
        to = (tx.get("to_address") or "").lower()
        if fr in watch or to in watch:
            out.append(tx)
    return out

def escolher_coletor() -> str:
    """LÃª coletor de CLI/env. PadrÃ£o: mock."""
    for i, a in enumerate(sys.argv):
        if a in ("--collector", "-c") and i + 1 < len(sys.argv):
            return sys.argv[i + 1].strip().lower()
        if a.startswith("--collector="):
            return a.split("=", 1)[1].strip().lower()
    return os.getenv("COLLECTOR", "mock").strip().lower()

def parse_flag(name: str) -> bool:
    """Retorna True se a flag (ex.: --daemon) estiver presente na CLI."""
    return any(arg == f"--{name}" for arg in sys.argv)

def parse_kv(name: str, default: str | None = None) -> str | None:
    """LÃª parÃ¢metro estilo --interval=15; se ausente, retorna default."""
    for a in sys.argv:
        if a.startswith(f"--{name}="):
            return a.split("=", 1)[1]
    return default

# ---------------------- ExecuÃ§Ã£o de 1 passada ---------------------- #
def run_once(collector: str,
             engine: ScoreEngine,
             alerter: TelegramAlerter,
             limiar: int,
             chain_label: str,
             seen: Set[str],
             watch: Set[str],
             require_match: bool) -> Tuple[int, int]:
    """
    Executa UMA coleta + scoring + persistÃªncia.
    Retorna (novas_transacoes_persistidas, qtd_pendentes_geradas)
    """
    # 1) Coleta
    if collector == "eth":
        load_from_eth = try_load_eth_collector()
        if load_from_eth is None:
            print("[WARN] Coletor ETH indisponÃ­vel. Usando mock.")
            txs = load_input_or_mock(DATA_DIR)
        else:
            txs = load_from_eth(DATA_DIR) or []
            if not txs:
                print("[WARN] Coletor ETH nÃ£o retornou dados. Usando mock.")
                txs = load_input_or_mock(DATA_DIR)
    else:
        txs = load_input_or_mock(DATA_DIR)

    # 2) Filtro por carteiras monitoradas (se requerido)
    txs = filter_by_addresses(txs, watch, require_match)

    # 3) Dedup por tx_id
    txs = [t for t in txs if t.get("tx_id") and t["tx_id"] not in seen]
    if not txs:
        return (0, 0)

    # 4) Scoring e explicabilidade
    out_rows: List[Dict[str, Any]] = []
    pendings: List[Dict[str, Any]] = []

    for tx in txs:
        scored = engine.score_transaction(tx)
        hits: Dict[str, int] = scored["hits"] or {}
        penalty_total = int(sum(hits.values()))
        contrib_pct = {k: round((v / penalty_total) * 100, 1) for k, v in hits.items()} if penalty_total > 0 else {}
        explain_payload = {"weights": hits, "contrib_pct": contrib_pct}

        reasons_txt = safe_text("; ".join(scored["reasons"]) if scored["reasons"] else "")
        row = {
            "tx_id": tx.get("tx_id",""),
            "timestamp": tx.get("timestamp",""),
            "from_address": (tx.get("from_address","") or "").lower(),
            "to_address": (tx.get("to_address","") or "").lower(),
            "amount": tx.get("amount",0),
            "token": tx.get("token",""),
            "method": tx.get("method",""),
            "chain": chain_label,
            "is_new_address": "yes" if hits.get("new_address") else "no",
            "velocity_last_window": scored.get("velocity_last_window", 0),
            "score": scored["score"],
            "penalty_total": penalty_total,
            "reasons": reasons_txt,
            "explain": json.dumps(explain_payload, ensure_ascii=False),
        }
        out_rows.append(row)

        # Atualiza base de conhecidos
        if hits.get("new_address"):
            append_known_address(tx.get("from_address",""))

        # Alerta se crÃ­tico
        if row["score"] < limiar:
            pendings.append(row)
            msg = (
                f"ðŸš¨ SafeScore ALERTA\n"
                f"TX: {row['tx_id']}\n"
                f"Score: {row['score']} (< {limiar})\n"
                f"De: {abbreviate(row['from_address'])}\n"
                f"Para: {abbreviate(row['to_address'])}\n"
                f"Valor: {row['amount']} {row['token']}\n"
                f"Motivos: {row['reasons'] or 'n/d'}"
            )
            alerter.send(msg)

    # 5) PersistÃªncia
    write_transactions(out_rows)
    if pendings:
        append_pending(pendings)

    # 6) Atualiza 'seen' (dedupe) e histÃ³rico para VELOCIDADE
    seen.update(r["tx_id"] for r in out_rows if r.get("tx_id"))
    # Acrescenta ao histÃ³rico na memÃ³ria (para prÃ³xima janela de velocidade)
    engine.prev.extend(out_rows)

    return (len(out_rows), len(pendings))

# ---------------------- CLI ---------------------- #
def main():
    ensure_data_files()

    try:
        limiar = int(os.getenv("SCORE_ALERT_THRESHOLD", "50"))
    except Exception:
        limiar = 50

    collector = escolher_coletor()
    chain_label = os.getenv("CHAIN_NAME", "ETH") if collector == "eth" else "MOCK"

    # Engine/alertas
    prev = read_prev_transactions()
    known = read_known_addresses()
    engine = ScoreEngine(data_dir=str(DATA_DIR), prev_transactions=prev, known_addresses=known)
    alerter = TelegramAlerter.from_env()

    # Monitoramento/endereÃ§os
    from_watchlist = parse_flag("monitor-watchlist")
    extra_cli = parse_kv("monitor-addresses")
    extra_env = os.getenv("ETH_MONITOR_ADDRESSES")
    require_match = parse_flag("require-match")
    watch = load_watch_addresses(from_watchlist, extra_cli, extra_env)
    if watch:
        print(f"[INFO] Monitorando {len(watch)} endereÃ§o(s). "
              f"{'Processando apenas matches (--require-match ativado).' if require_match else 'Processando tudo e usando watchlist para score.'}")

    # Modo Daemon?
    daemon = parse_flag("daemon")
    interval_s = int(parse_kv("interval", os.getenv("POLL_SECONDS", "20")) or "20")

    # Dedup inicial
    seen = load_seen_tx_ids()

    if not daemon:
        new_rows, new_pend = run_once(collector, engine, alerter, limiar, chain_label, seen, watch, require_match)
        print(f"[OK] Coletor '{collector}': {new_rows} nova(s) transaÃ§Ã£o(Ãµes) persistida(s).")
        if new_pend:
            print(f"[HOLD] {new_pend} transaÃ§Ã£o(Ãµes) crÃ­tica(s) adicionada(s) a {PENDING_CSV.name} (score < {limiar}).")
        else:
            print("[HOLD] Nenhuma transaÃ§Ã£o crÃ­tica para retenÃ§Ã£o.")
        return

    # Loop contÃ­nuo
    print(f"[DAEMON] Iniciando loop: coletor='{collector}', intervalo={interval_s}s. "
          f"{'(somente matches)' if require_match else '(todas as tx, com score em watchlist se aplicÃ¡vel)'}")
    try:
        while True:
            start = time.time()
            new_rows, new_pend = run_once(collector, engine, alerter, limiar, chain_label, seen, watch, require_match)
            ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print(f"[{ts}] Tick: +{new_rows} novas, +{new_pend} crÃ­ticas. Total seen={len(seen)}.")
            # Dorme o restante do perÃ­odo
            elapsed = time.time() - start
            sleep_for = max(1.0, interval_s - elapsed)
            time.sleep(sleep_for)
    except KeyboardInterrupt:
        print("\n[DAEMON] Encerrado pelo usuÃ¡rio.")

if __name__ == "__main__":
    main()
